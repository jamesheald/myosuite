Launching a python run
Thu Sep 11 04:21:35 PM UTC 2025
Active conda env: /nfs/nhome/live/jheald/miniconda3/envs/myoarmdm
/nfs/nhome/live/jheald/miniconda3/envs/myoarmdm/bin/python3
/nfs/nhome/live/jheald/miniconda3/envs/myoarmdm/bin/pip
2025-09-11 16:21:39.337606: I external/xla/xla/pjrt/pjrt_api.cc:118] GetPjrtApi was found for cuda at /nfs/nhome/live/jheald/miniconda3/envs/myoarmdm/lib/python3.13/site-packages/jax_plugins/xla_cuda12/xla_cuda_plugin.so
2025-09-11 16:21:39.337750: I external/xla/xla/pjrt/pjrt_api.cc:96] PJRT_Api is set for device type cuda
2025-09-11 16:21:39.343863: I external/xla/xla/pjrt/pjrt_api.cc:167] The PJRT plugin has PJRT API version 0.75. The framework PJRT API version is 0.75.
2025-09-11 16:21:39.570789: I external/xla/xla/service/service.cc:163] XLA service 0x5fb4d9fb3460 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-09-11 16:21:39.570822: I external/xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA RTX A4500, Compute Capability 8.6
2025-09-11 16:21:39.586538: I external/xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91002
2025-09-11 16:21:39.586801: I external/xla/xla/pjrt/pjrt_c_api_client.cc:133] PjRtCApiClient created.
Current backend: gpu
MyoSuite:> Registering Myo Envs
Warp 1.10.0.dev20250903 initialized:
   Git commit: 531f4e35cc5e5a524559a2350adf50184dd6d289
   CUDA Toolkit 12.8, Driver 12.9
   Devices:
     "cpu"      : "x86_64"
     "cuda:0"   : "NVIDIA RTX A4500" (20 GiB, sm_86, mempool enabled)
   Kernel cache:
     /nfs/nhome/live/jheald/.cache/warp/1.10.0.dev20250903
Training on environment:
MjxHandReachRandom-v0
Environment Config:
ctrl_dt: 0.01
far_th: 0.034
model_path: !!python/object/apply:etils.epath.gpath.PosixGPath
- /nfs/nhome/live/jheald/myosuite/myosuite
- envs/myo/assets/hand/
- myohand_pose.xml
reward_weights:
  bonus: 4.0
  penalty: 50.0
  reach: 1.0
sim_dt: 0.002
target_reach_range:
  IFtip: !!python/object/apply:jax._src.array._reconstruct_array
  - &id001 !!python/name:numpy._core.multiarray._reconstruct ''
  - !!python/tuple
    - &id002 !!python/name:numpy.ndarray ''
    - !!python/tuple
      - 0
    - !!binary |
      Yg==
  - !!python/tuple
    - 1
    - !!python/tuple
      - 2
      - 3
    - &id003 !!python/object/apply:numpy.dtype
      args:
      - f4
      - false
      - true
      state: !!python/tuple
      - 3
      - <
      - null
      - null
      - null
      - -1
      - -1
      - 0
    - false
    - !!binary |
      gZVDvukmEb/D9bg/+FPjvXnpBr8fhbs/
  - weak_type: false
  LFtip: !!python/object/apply:jax._src.array._reconstruct_array
  - *id001
  - !!python/tuple
    - *id002
    - !!python/tuple
      - 0
    - !!binary |
      Yg==
  - !!python/tuple
    - 1
    - !!python/tuple
      - 2
      - 3
    - *id003
    - false
    - !!binary |
      EoNAvrpJDL+iRbY/Gy/dvUoMAr/+1Lg/
  - weak_type: false
  MFtip: !!python/object/apply:jax._src.array._reconstruct_array
  - *id001
  - !!python/tuple
    - *id002
    - !!python/tuple
      - 0
    - !!binary |
      Yg==
  - !!python/tuple
    - 1
    - !!python/tuple
      - 2
      - 3
    - *id003
    - false
    - !!binary |
      yXY+vukmEb+e77c/hxbZvXnpBr/6fro/
  - weak_type: false
  RFtip: !!python/object/apply:jax._src.array._reconstruct_array
  - *id001
  - !!python/tuple
    - *id002
    - !!python/tuple
      - 0
    - !!binary |
      Yg==
  - !!python/tuple
    - 1
    - !!python/tuple
      - 2
      - 3
    - *id003
    - false
    - !!binary |
      EoNAvsUgEL8Urrc/Gy/dvVTjBb9xPbo/
  - weak_type: false
  THtip: !!python/object/apply:jax._src.array._reconstruct_array
  - *id001
  - !!python/tuple
    - *id002
    - !!python/tuple
      - 0
    - !!binary |
      Yg==
  - !!python/tuple
    - 1
    - !!python/tuple
      - 2
      - 3
    - *id003
    - false
    - !!binary |
      pHA9vka2E79xPbo/AAAAvh1aBL/hesQ/
  - weak_type: false

PPO Training Parameters:
action_repeat: 1
batch_size: 128
clipping_epsilon: 0.3
discounting: 0.95
entropy_cost: 0.001
episode_length: 150
learning_rate: 0.0003
max_grad_norm: 1.0
network_factory:
  policy_hidden_layer_sizes: &id001 !!python/tuple
  - 64
  - 64
  - 64
  policy_obs_key: state
  value_hidden_layer_sizes: *id001
  value_obs_key: state
normalize_observations: true
num_envs: 1024
num_eval_envs: 128
num_evals: 200
num_minibatches: 8
num_resets_per_eval: 1
num_timesteps: 50000000
num_updates_per_batch: 8
reward_scaling: 1.0
unroll_length: 10

wandb: Currently logged in as: james-heald (james-gatsby) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: creating run
wandb: Tracking run with wandb version 0.21.3
wandb: Run data is saved locally in /nfs/nhome/live/jheald/myosuite/myosuite/envs/myo/mjx/wandb/run-20250911_162156-s8rwjmoo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-resonance-3
wandb: â­ï¸ View project at https://wandb.ai/james-gatsby/MjxHandReachRandom-v0
wandb: ðŸš€ View run at https://wandb.ai/james-gatsby/MjxHandReachRandom-v0/runs/s8rwjmoo
Module mujoco.mjx.third_party.mujoco_warp._src.smooth 70ca803 load on device 'cuda:0' took 15.86 ms  (cached)
Module mujoco.mjx.third_party.mujoco_warp._src.collision_driver 685d542 load on device 'cuda:0' took 6.18 ms  (cached)
Module mujoco.mjx.third_party.mujoco_warp._src.collision_driver._nxn_broadphase c2383b2 load on device 'cuda:0' took 7.49 ms  (cached)
Module mujoco.mjx.third_party.mujoco_warp._src.collision_convex.ccd_kernel_builder e37fe54 load on device 'cuda:0' took 231.49 ms  (cached)
Module mujoco.mjx.third_party.mujoco_warp._src.collision_convex.ccd_kernel_builder b3c7ec9 load on device 'cuda:0' took 29829.70 ms  (compiled)
Module mujoco.mjx.third_party.mujoco_warp._src.collision_convex.ccd_kernel_builder 87be61f load on device 'cuda:0' took 40094.98 ms  (compiled)
Module mujoco.mjx.third_party.mujoco_warp._src.collision_convex.ccd_kernel_builder 143a9b2 load on device 'cuda:0' took 52594.09 ms  (compiled)
Module mujoco.mjx.third_party.mujoco_warp._src.collision_primitive 1fe0c8d load on device 'cuda:0' took 1298.94 ms  (compiled)
Module mujoco.mjx.third_party.mujoco_warp._src.constraint ac9e3a1 load on device 'cuda:0' took 8.67 ms  (cached)
Module mujoco.mjx.third_party.mujoco_warp._src.forward 4003be6 load on device 'cuda:0' took 6.85 ms  (cached)
Module mujoco.mjx.third_party.mujoco_warp._src.forward._actuator_velocity e7736d2 load on device 'cuda:0' took 515.99 ms  (compiled)
Module mujoco.mjx.third_party.mujoco_warp._src.forward._tendon_velocity 9de232a load on device 'cuda:0' took 553.22 ms  (compiled)
Module mujoco.mjx.third_party.mujoco_warp._src.passive 123e0f6 load on device 'cuda:0' took 6.72 ms  (cached)
Module mujoco.mjx.third_party.mujoco_warp._src.support 9e4f16a load on device 'cuda:0' took 7.53 ms  (cached)
Module mujoco.mjx.third_party.mujoco_warp._src.smooth._tile_cholesky_factorize_solve bf4b5bf load on device 'cuda:0' took 6298.95 ms  (compiled)
Module mujoco.mjx.third_party.mujoco_warp._src.solver 69793be load on device 'cuda:0' took 7.93 ms  (cached)
Module mujoco.mjx.third_party.mujoco_warp._src.support.mul_m_dense 13ffcf8 load on device 'cuda:0' took 9242.17 ms  (compiled)
Module mujoco.mjx.third_party.mujoco_warp._src.solver.update_constraint_gauss_cost bb02603 load on device 'cuda:0' took 735.46 ms  (compiled)
Module mujoco.mjx.third_party.mujoco_warp._src.solver.update_gradient_cholesky a659335 load on device 'cuda:0' took 5540.92 ms  (compiled)
Module mujoco.mjx.third_party.mujoco_warp._src.solver.linesearch_jv_fused edec209 load on device 'cuda:0' took 559.24 ms  (compiled)
Module mujoco.mjx.third_party.mujoco_warp._src.forward._tile_euler_dense 8842fce load on device 'cuda:0' took 3217.39 ms  (compiled)
Module mujoco.mjx.warp.ffi 525be0e load on device 'cuda:0' took 5.70 ms  (cached)
2025-09-11 16:24:40.031318: I external/xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.
2025-09-11 16:24:40.031376: I external/xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.
2025-09-11 16:24:40.031412: I external/xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.
2025-09-11 16:24:49.327801: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:349] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_general_19', 164 bytes spill stores, 164 bytes spill loads

Step 0 at 1406643.636672233: reward=-47.619
/nfs/nhome/live/jheald/miniconda3/envs/myoarmdm/lib/python3.13/subprocess.py:1902: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.
  self.pid = _fork_exec(
2025-09-11 16:25:39.975065: I external/xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.
2025-09-11 16:25:39.975152: I external/xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.
2025-09-11 16:25:39.975197: I external/xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.
2025-09-11 16:25:39.975250: I external/xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.
2025-09-11 16:25:39.975283: I external/xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.
2025-09-11 16:25:39.975331: I external/xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.
2025-09-11 16:25:39.975363: I external/xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.
2025-09-11 16:25:39.975679: I external/xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.
2025-09-11 16:25:39.975718: I external/xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.
2025-09-11 16:25:39.975757: I external/xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.
2025-09-11 16:25:47.970340: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:349] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 196 bytes spill stores, 196 bytes spill loads

2025-09-11 16:26:01.443265: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:349] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 16 bytes spill stores, 16 bytes spill loads

2025-09-11 16:26:11.716273: I external/xla/xla/stream_executor/cuda/subprocess_compilation.cc:349] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_general_45', 196 bytes spill stores, 196 bytes spill loads

Step 256000 at 1406768.474589849: reward=-44.566
Step 512000 at 1406818.693837882: reward=-35.855
Step 768000 at 1406883.281899254: reward=-9.762
Step 1024000 at 1406936.231755148: reward=6.146
Step 1280000 at 1406982.997941134: reward=-4.237
Step 1536000 at 1407039.226284197: reward=12.715
Step 1792000 at 1407090.89146763: reward=-6.295
Step 2048000 at 1407148.808315317: reward=-7.522
Step 2304000 at 1407200.604796262: reward=25.948
Step 2560000 at 1407255.646695468: reward=46.487
Step 2816000 at 1407315.020200547: reward=60.804
Step 3072000 at 1407374.584852686: reward=54.180
Step 3328000 at 1407443.76568141: reward=91.949
Step 3584000 at 1407518.693075117: reward=63.954
Step 3840000 at 1407605.497360638: reward=100.246
Step 4096000 at 1407688.774106303: reward=57.036
Step 4352000 at 1407768.160619867: reward=81.249
Step 4608000 at 1407821.423874416: reward=55.378
Step 4864000 at 1407930.15386569: reward=114.004
Step 5120000 at 1407998.292349296: reward=140.296
Step 5376000 at 1408146.345305162: reward=83.851
Step 5632000 at 1408261.627965885: reward=105.290
Step 5888000 at 1408326.372785566: reward=132.758
Step 6144000 at 1408385.448951631: reward=110.450
Step 6400000 at 1408453.576607893: reward=83.317
Step 6656000 at 1408625.728618785: reward=104.404
Step 6912000 at 1408742.537266464: reward=145.708
Step 7168000 at 1408934.08135604: reward=110.019
Step 7424000 at 1409101.829713257: reward=84.799
Step 7680000 at 1409210.179401508: reward=167.264
Step 7936000 at 1409324.762594472: reward=120.029
Step 8192000 at 1409535.054670326: reward=75.214
Step 8448000 at 1409610.441556021: reward=125.911
Step 8704000 at 1409692.510063907: reward=67.332
Step 8960000 at 1409894.600413416: reward=103.582
Step 9216000 at 1409992.975455136: reward=94.891
Step 9472000 at 1410116.197517421: reward=91.628
Traceback (most recent call last):
  File "/nfs/nhome/live/jheald/myosuite/myosuite/envs/myo/mjx/my_train.py", line 148, in <module>
    main("MjxHandReachRandom-v0")
    ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/nfs/nhome/live/jheald/myosuite/myosuite/envs/myo/mjx/my_train.py", line 105, in main
    make_inference_fn, params, _ = ppo.train(
                                   ~~~~~~~~~^
        environment=env,
        ^^^^^^^^^^^^^^^^
    ...<4 lines>...
        **ppo_params,
        ^^^^^^^^^^^^^
    )
    ^
  File "/nfs/nhome/live/jheald/miniconda3/envs/myoarmdm/lib/python3.13/site-packages/brax/training/agents/ppo/train.py", line 727, in train
    policy_params_fn(current_step, make_policy, params)
    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/nfs/nhome/live/jheald/myosuite/myosuite/envs/myo/mjx/my_train.py", line 90, in policy_params_fn
    frame = eval_env.render(state, height=240, width=320, camera=cam_name)
  File "/nfs/nhome/live/jheald/mujoco_playground/mujoco_playground/_src/wrapper.py", line 82, in render
    return self.env.render(
           ~~~~~~~~~~~~~~~^
        trajectory, height, width, camera, scene_option, modify_scene_fns
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/nfs/nhome/live/jheald/mujoco_playground/mujoco_playground/_src/mjx_env.py", line 303, in render
    return render_array(
        self.mj_model,
    ...<5 lines>...
        modify_scene_fns=modify_scene_fns,
    )
  File "/nfs/nhome/live/jheald/mujoco_playground/mujoco_playground/_src/mjx_env.py", line 331, in render_array
    renderer = mujoco.Renderer(mj_model, height=height, width=width)
  File "/nfs/nhome/live/jheald/miniconda3/envs/myoarmdm/lib/python3.13/site-packages/mujoco/renderer.py", line 89, in __init__
    self._mjr_context = _render.MjrContext(model, font_scale.value)
                        ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^
mujoco.FatalError: Offscreen framebuffer is not complete, error 0x8cdd
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mproud-resonance-3[0m at: [34mhttps://wandb.ai/james-gatsby/MjxHandReachRandom-v0/runs/s8rwjmoo[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250911_162156-s8rwjmoo/logs[0m
